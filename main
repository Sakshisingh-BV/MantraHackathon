import React, { useState, useRef, useEffect } from 'react';
import { Upload, Video, Send, MessageCircle, Clock, AlertTriangle, CheckCircle, Play, Pause, RotateCcw } from 'lucide-react';

const VisualChatAssistant = () => {
  const [currentVideo, setCurrentVideo] = useState(null);
  const [videoUrl, setVideoUrl] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);
  const [videoAnalysis, setVideoAnalysis] = useState(null);
  const [chatHistory, setChatHistory] = useState([]);
  const [currentMessage, setCurrentMessage] = useState('');
  const [isVideoPlaying, setIsVideoPlaying] = useState(false);
  const [currentTime, setCurrentTime] = useState(0);
  const [videoDuration, setVideoDuration] = useState(0);
  
  const videoRef = useRef(null);
  const fileInputRef = useRef(null);
  const chatEndRef = useRef(null);

  // Sample analysis data (in a real implementation, this would come from your backend)
  const sampleAnalysis = {
    duration: 8,
    events: [
      {
        timestamp: 3.2,
        type: 'pedestrian_crossing',
        description: 'Pedestrian runs across the road in front of camera',
        severity: 'high',
        guideline_violation: true
      },
      {
        timestamp: 1.5,
        type: 'vehicle_movement',
        description: 'White car in left lane maintaining steady speed',
        severity: 'low',
        guideline_violation: false
      },
      {
        timestamp: 5.8,
        type: 'traffic_flow',
        description: 'Multiple vehicles navigating through urban traffic',
        severity: 'medium',
        guideline_violation: false
      }
    ],
    summary: 'Urban motorcycle ride capturing unexpected pedestrian crossing. The video shows a first-person view from a motorcycle on a multi-lane road. Key event: pedestrian jogs across traffic at 3.2s timestamp. Vehicle continues forward without evasive action.',
    violations: [
      'Pedestrian crossing against traffic flow at 00:03'
    ],
    vehicle_type: 'motorcycle',
    environment: 'urban road, late afternoon lighting'
  };

  const predefinedQuestions = [
    "What is the most significant event in this video?",
    "How did the camera vehicle react to the pedestrian?",
    "Describe the overall scene and environment",
    "What traffic violations were detected?",
    "What type of vehicle is the camera mounted on?"
  ];

  useEffect(() => {
    chatEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [chatHistory]);

  const handleVideoUpload = (event) => {
    const file = event.target.files[0];
    if (file && file.type.startsWith('video/')) {
      if (file.size > 50 * 1024 * 1024) { // 50MB limit for demo
        alert('Video file size should be less than 50MB for this demo');
        return;
      }
      
      const url = URL.createObjectURL(file);
      setVideoUrl(url);
      setCurrentVideo(file);
      setVideoAnalysis(null);
      setChatHistory([]);
    }
  };

  const processVideo = async () => {
    if (!currentVideo) return;
    
    setIsProcessing(true);
    
    // Simulate video processing (in real implementation, send to backend)
    await new Promise(resolve => setTimeout(resolve, 3000));
    
    setVideoAnalysis(sampleAnalysis);
    setIsProcessing(false);
    
    // Add initial analysis to chat
    const initialMessage = {
      type: 'analysis',
      content: `Video processed successfully! Duration: ${sampleAnalysis.duration}s\n\n**Summary:** ${sampleAnalysis.summary}\n\n**Key Events Detected:**\n${sampleAnalysis.events.map(event => `â€¢ ${event.description} (${event.timestamp}s)`).join('\n')}\n\n**Violations:** ${sampleAnalysis.violations.length > 0 ? sampleAnalysis.violations.join(', ') : 'None detected'}`,
      timestamp: new Date().toLocaleTimeString()
    };
    
    setChatHistory([initialMessage]);
  };

  const handleSendMessage = async () => {
    if (!currentMessage.trim() || !videoAnalysis) return;
    
    const userMessage = {
      type: 'user',
      content: currentMessage,
      timestamp: new Date().toLocaleTimeString()
    };
    
    setChatHistory(prev => [...prev, userMessage]);
    const question = currentMessage;
    setCurrentMessage('');
    
    // Simulate AI response (in real implementation, send to backend)
    setTimeout(() => {
      let response = '';
      
      if (question.toLowerCase().includes('significant') || question.toLowerCase().includes('unexpected')) {
        response = 'The most significant and unexpected event occurs at the 3.2-second mark when a pedestrian suddenly runs across the road directly in front of the camera. This creates a potentially dangerous situation as the pedestrian crosses against the flow of traffic.';
      } else if (question.toLowerCase().includes('react') || question.toLowerCase().includes('camera vehicle')) {
        response = 'After the pedestrian crosses, the camera vehicle (motorcycle) continues to drive forward in its lane without any drastic reaction. There\'s no sharp braking, swerving, or stopping - the motorcycle maintains its course and speed.';
      } else if (question.toLowerCase().includes('scene') || question.toLowerCase().includes('environment')) {
        response = 'The video shows a first-person view from a motorcycle on a multi-lane urban road during late afternoon. The environment features large buildings, trees lining the road, and moderate traffic with various vehicles including a white hatchback and black sedan. The lighting suggests late afternoon conditions.';
      } else if (question.toLowerCase().includes('violation') || question.toLowerCase().includes('guideline')) {
        response = 'The main traffic violation detected is the pedestrian crossing against traffic flow at the 3-second mark. This represents unsafe pedestrian behavior as they cross a busy multi-lane road without proper clearance.';
      } else if (question.toLowerCase().includes('vehicle type') || question.toLowerCase().includes('mounted')) {
        response = 'Based on the camera perspective, movement pattern, and field of view, the camera is mounted on a motorcycle. This is evident from the riding position and the way the vehicle navigates through traffic.';
      } else {
        response = 'Based on the video analysis, I can help you understand the events, timeline, and any guideline violations. The key event was a pedestrian crossing at 3.2 seconds. Would you like me to elaborate on any specific aspect?';
      }
      
      const aiMessage = {
        type: 'assistant',
        content: response,
        timestamp: new Date().toLocaleTimeString()
      };
      
      setChatHistory(prev => [...prev, aiMessage]);
    }, 1000);
  };

  const handleQuickQuestion = (question) => {
    setCurrentMessage(question);
  };

  const togglePlayPause = () => {
    if (videoRef.current) {
      if (isVideoPlaying) {
        videoRef.current.pause();
      } else {
        videoRef.current.play();
      }
      setIsVideoPlaying(!isVideoPlaying);
    }
  };

  const handleTimeUpdate = () => {
    if (videoRef.current) {
      setCurrentTime(videoRef.current.currentTime);
    }
  };

  const handleLoadedMetadata = () => {
    if (videoRef.current) {
      setVideoDuration(videoRef.current.duration);
    }
  };

  const seekTo = (timestamp) => {
    if (videoRef.current) {
      videoRef.current.currentTime = timestamp;
      setCurrentTime(timestamp);
    }
  };

  const formatTime = (seconds) => {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-blue-50 to-indigo-100">
      <div className="container mx-auto px-4 py-8">
        <div className="text-center mb-8">
          <h1 className="text-4xl font-bold text-gray-800 mb-2">Visual Understanding Chat Assistant</h1>
          <p className="text-lg text-gray-600">Upload a video, analyze events, and chat about what you see</p>
        </div>

        <div className="grid grid-cols-1 lg:grid-cols-2 gap-8">
          {/* Video Section */}
          <div className="bg-white rounded-xl shadow-lg p-6">
            <h2 className="text-2xl font-semibold mb-4 flex items-center">
              <Video className="mr-2" /> Video Analysis
            </h2>
            
            {!videoUrl ? (
              <div 
                className="border-2 border-dashed border-blue-300 rounded-lg p-8 text-center cursor-pointer hover:border-blue-500 transition-colors"
                onClick={() => fileInputRef.current?.click()}
              >
                <Upload className="mx-auto mb-4 text-blue-500" size={48} />
                <p className="text-lg text-gray-600 mb-2">Click to upload video</p>
                <p className="text-sm text-gray-500">Max 2 minutes, up to 50MB</p>
                <input
                  ref={fileInputRef}
                  type="file"
                  accept="video/*"
                  onChange={handleVideoUpload}
                  className="hidden"
                />
              </div>
            ) : (
              <div className="space-y-4">
                <div className="relative bg-black rounded-lg overflow-hidden">
                  <video
                    ref={videoRef}
                    src={videoUrl}
                    className="w-full h-64 object-contain"
                    onTimeUpdate={handleTimeUpdate}
                    onLoadedMetadata={handleLoadedMetadata}
                    onEnded={() => setIsVideoPlaying(false)}
                  />
                  
                  <div className="absolute bottom-4 left-4 right-4">
                    <div className="flex items-center space-x-2 bg-black bg-opacity-50 rounded-lg p-2">
                      <button
                        onClick={togglePlayPause}
                        className="text-white hover:text-blue-300 transition-colors"
                      >
                        {isVideoPlaying ? <Pause size={20} /> : <Play size={20} />}
                      </button>
                      <div className="flex-1 bg-gray-600 rounded-full h-1">
                        <div
                          className="bg-blue-500 h-1 rounded-full transition-all"
                          style={{ width: `${(currentTime / videoDuration) * 100}%` }}
                        />
                      </div>
                      <span className="text-white text-sm">
                        {formatTime(currentTime)} / {formatTime(videoDuration)}
                      </span>
                    </div>
                  </div>
                </div>
                
                <div className="flex space-x-2">
                  <button
                    onClick={processVideo}
                    disabled={isProcessing}
                    className="flex-1 bg-blue-600 text-white py-3 px-4 rounded-lg hover:bg-blue-700 disabled:opacity-50 disabled:cursor-not-allowed transition-colors flex items-center justify-center"
                  >
                    {isProcessing ? (
                      <div className="animate-spin rounded-full h-5 w-5 border-b-2 border-white mr-2" />
                    ) : (
                      <MessageCircle className="mr-2" size={20} />
                    )}
                    {isProcessing ? 'Analyzing...' : 'Analyze Video'}
                  </button>
                  
                  <button
                    onClick={() => fileInputRef.current?.click()}
                    className="bg-gray-600 text-white py-3 px-4 rounded-lg hover:bg-gray-700 transition-colors"
                  >
                    <RotateCcw size={20} />
                  </button>
                </div>
              </div>
            )}

            {/* Event Timeline */}
            {videoAnalysis && (
              <div className="mt-6 bg-gray-50 rounded-lg p-4">
                <h3 className="font-semibold mb-3 flex items-center">
                  <Clock className="mr-2" size={18} /> Event Timeline
                </h3>
                <div className="space-y-2">
                  {videoAnalysis.events.map((event, index) => (
                    <div
                      key={index}
                      className={`p-3 rounded cursor-pointer transition-colors ${
                        event.guideline_violation 
                          ? 'bg-red-100 border-l-4 border-red-500' 
                          : 'bg-green-100 border-l-4 border-green-500'
                      }`}
                      onClick={() => seekTo(event.timestamp)}
                    >
                      <div className="flex items-center justify-between">
                        <span className="font-medium">{formatTime(event.timestamp)}</span>
                        {event.guideline_violation ? (
                          <AlertTriangle className="text-red-500" size={16} />
                        ) : (
                          <CheckCircle className="text-green-500" size={16} />
                        )}
                      </div>
                      <p className="text-sm text-gray-700 mt-1">{event.description}</p>
                    </div>
                  ))}
                </div>
              </div>
            )}
          </div>

          {/* Chat Section */}
          <div className="bg-white rounded-xl shadow-lg p-6 flex flex-col">
            <h2 className="text-2xl font-semibold mb-4 flex items-center">
              <MessageCircle className="mr-2" /> Chat Assistant
            </h2>
            
            {!videoAnalysis ? (
              <div className="flex-1 flex items-center justify-center text-gray-500">
                <div className="text-center">
                  <MessageCircle size={64} className="mx-auto mb-4 opacity-50" />
                  <p>Upload and analyze a video to start chatting</p>
                </div>
              </div>
            ) : (
              <>
                <div className="flex-1 overflow-y-auto mb-4 space-y-4 max-h-96">
                  {chatHistory.map((message, index) => (
                    <div
                      key={index}
                      className={`p-4 rounded-lg ${
                        message.type === 'user'
                          ? 'bg-blue-600 text-white ml-8'
                          : message.type === 'assistant'
                          ? 'bg-gray-100 text-gray-800 mr-8'
                          : 'bg-green-50 text-gray-800 border border-green-200'
                      }`}
                    >
                      <div className="whitespace-pre-wrap text-sm">
                        {message.content}
                      </div>
                      <div className={`text-xs mt-2 opacity-70 ${
                        message.type === 'user' ? 'text-blue-100' : 'text-gray-500'
                      }`}>
                        {message.timestamp}
                      </div>
                    </div>
                  ))}
                  <div ref={chatEndRef} />
                </div>

                {/* Quick Questions */}
                <div className="mb-4">
                  <p className="text-sm text-gray-600 mb-2">Quick questions:</p>
                  <div className="flex flex-wrap gap-2">
                    {predefinedQuestions.map((question, index) => (
                      <button
                        key={index}
                        onClick={() => handleQuickQuestion(question)}
                        className="text-xs bg-blue-100 text-blue-700 px-3 py-1 rounded-full hover:bg-blue-200 transition-colors"
                      >
                        {question}
                      </button>
                    ))}
                  </div>
                </div>

                {/* Message Input */}
                <div className="flex space-x-2">
                  <input
                    type="text"
                    value={currentMessage}
                    onChange={(e) => setCurrentMessage(e.target.value)}
                    onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
                    placeholder="Ask about the video events..."
                    className="flex-1 border border-gray-300 rounded-lg px-4 py-2 focus:outline-none focus:border-blue-500"
                  />
                  <button
                    onClick={handleSendMessage}
                    disabled={!currentMessage.trim()}
                    className="bg-blue-600 text-white px-4 py-2 rounded-lg hover:bg-blue-700 disabled:opacity-50 disabled:cursor-not-allowed transition-colors"
                  >
                    <Send size={20} />
                  </button>
                </div>
              </>
            )}
          </div>
        </div>

        {/* Features Overview */}
        <div className="mt-12 bg-white rounded-xl shadow-lg p-8">
          <h2 className="text-2xl font-semibold mb-6 text-center">Features Demonstrated</h2>
          <div className="grid grid-cols-1 md:grid-cols-3 gap-6">
            <div className="text-center">
              <Video className="mx-auto mb-3 text-blue-600" size={40} />
              <h3 className="font-semibold mb-2">Video Processing</h3>
              <p className="text-gray-600 text-sm">Upload and analyze videos up to 2 minutes with event detection and timeline visualization</p>
            </div>
            <div className="text-center">
              <AlertTriangle className="mx-auto mb-3 text-orange-600" size={40} />
              <h3 className="font-semibold mb-2">Guideline Detection</h3>
              <p className="text-gray-600 text-sm">Automatically identify traffic violations and safety guideline adherence</p>
            </div>
            <div className="text-center">
              <MessageCircle className="mx-auto mb-3 text-green-600" size={40} />
              <h3 className="font-semibold mb-2">Multi-turn Chat</h3>
              <p className="text-gray-600 text-sm">Natural conversation with context retention and intelligent responses about video content</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
};

export default VisualChatAssistant;
